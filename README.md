# VGG16-implementation-for-Classifying-Anatomical-Structures-in-2D-fetal-Ultrasounds

# Abstract
This research project aims to investigate how to employ Convolutional Neural Networks (CNN) in image classification. The project entails reading a related research paper, analyzing a supplied dataset, and then shortlisting architectures for feature extraction and classification using a fully connected neural network. Basic preprocessing techniques link images to their respective labels in the dataset and perform transformations. Transfer learning is then utilized to improve the performance of the CNN by leveraging the pre-trained Iights of a network trained on the ImageNet dataset. The network's convolutional layers are fixed, while only the weights of the fully connected layers are changed. The model's classification accuracy is validated by examining the outcomes of the training and validation datasets. Lastly, the model's performance is evaluated by sending test images across the network, and the results are assessed to determine the efficacy of the suggested methodology. Overall, this effort advances the science of computer vision and deep learning by investigating the use of CNNs in picture classification.

# Introduction
I decided to process the input photos using a modified VGG16 network. To ensure that the ML algorithms do not learn improperly, the target labels were one hot encoded beforehand. Several variables influenced the final model's selection: Several models, such as DenseNet-168, ResNeXt-101, and VGG16, shoId appreciable results in the research paper, but due to previous experience in constructing VGG16 and several tasks at hand in a short period of time - I found the implementation of VGG16 to be the appropriate choice due to prior working experience and because the other architectures did not provide a significant boost in accuracy. One disadvantage of using the VGG16 architecture was that the model built was the heaviest feasible, with around 134M trainable parameters.
